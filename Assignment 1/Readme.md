# CS685A: Assignment 1
## Analysis of Covid, Vaccination and Census Data

## Problem Description

* Can be found in the [Assignment](assignment1.pdf) file.

## Requirements:

* Python3 should be present on your system and should be accessible using the command `python3`

## Running the Project:

* To run the complete project in one go, execute [`assign1.sh`](assign1.sh)

```
./assign1.sh
```

* <a name="shell1"></a>To run a certain segment, use the following scripts:
    1. [`edge-generator.sh`](edge-generator.sh) : To solve Q1 and Q2
    2. [`case-generator.sh`](case-generator.sh) : To solve Q3
    3. [`peaks-generator.sh`](peaks-generator.sh) : To solve Q4
    4. [`vaccinated-count-generator.sh`](vaccinated-count-generator.sh) : To solve Q5
    5. [`vaccination-population-ratio-generator.sh`](vaccination-population-ratio-generator.sh) : To solve Q6
    6. [`vaccine-type-ratio-generator.sh`](vaccine-type-ratio-generator.sh) : To solve Q7
    7. [`vaccinated-ratio-generator.sh`](vaccinated-ratio-generator.sh) : To solve Q8
    8. [`complete-vaccination-generator.sh`](complete-vaccination-generator.sh) : To solve Q9

<p></p>

* The individual scripts need to be executed in the order in which they are mentioned, as the output generated by one script maybe needed for the execution of the further scripts.

## Project Structure:

### Directories:

* [out/](out/) : Stores the required output json and csv files.

* [data/](data/) : Modified and Refined data files used in the project.

* [meta/](meta/) : Stores the meta data (a set of json files) generated by the execution of scripts. The contents inside this folder ***should not*** be modified when the scripts are being executed. The folder can be deleted before beginning the execution of [`assign1.sh`](assign1.sh) or [`edge-generator.sh`](edge-generator.sh).

* [base/](base/) : Contains the initial unmodified data files.

* [update/](data/) : Redundant copy of [`data/`](data/), used for debugging and comparisons.

* [util/](util/) : Contains python script(s) that have snippets used to clean and refine the original data.

### Code Files:

#### Shell Scripts:

* Already described [here](#shell1).

#### Python Scripts:

* [meta.py](meta.py) : Converts the csv files to json format for use by the scripts later on. It also finds issues in multiple data sources (district pairs with edit distances < x, districts contained in another, etc.)

* [q1.py](q1.py) : Solves Question 1. Uses [`neighbor-districts.json`](data/neighbor-districts.json) and [`district_wise.csv`](data/district_wise.csv) to generate [`neighbor-districts-modified.json`](out/neighbor-districts-modified.json). See <b>[Explaination 1](#exp1)</b>.

* [q2.py](q2.py) : Creates au undirected graph from [`neighbor-districts-modified.json`](out/neighbor-districts-modified.json). This graph is printed in edge list format [`edge-graph.csv`](out/edge-graph.csv). See <b>[Explaination 2](#exp2)</b>.

* [q3.py](q3.py) : Uses [`districts.csv`](data/districts.csv) to determine the number of cases (weekly, monthly and overall) are reported for all districts (in [`cases-week.csv`](out/cases-week.csv), [`cases-month.csv`](out/cases-month.csv) and [`cases-overall.csv`](out/cases-overall.csv) respectively). See <b>[Explaination 3](#exp3)</b>.

* [q4.py](q4.py) : Find the 2 peaks on a district, state and overall level and generates [`district-peaks.csv`](out/district-peaks.csv), [`state-peaks.csv`](out/state-peaks.csv) and [`overall-peaks.csv`](out/overall-peaks.csv) respectively. See <b>[Explaination 4](#exp4)</b>.

* [q5.py](q5.py) : 

* [q6.py](q6.py) :

* [q7.py](q7.py) :

* [q8.py](q8.py) :

* [q9.py](q9.py) :

## Explaination:

* <a name="exp1"></a> The new json districts does a deep merge of the districts, i.e., if A, B and C are connected such that, originally A is a neighbour of B and B is a neighbour of C but A and C are not connected directly, now if B is to be removed, A and C will be reported as neighbours in the final answer.

* <a name="exp2"></a> DFS is used to generate the edge list. During DFS, parent history is maintained to prevent reporting duplicate edges. Edge list is printed directly (no header line is printed in the csv).

* <a name="exp3"></a> Calculates the endpoints of the weeks and months along with the weekid and then determines the cases by taking difference between the cumulative cases reported. The output file has the first line as the header.

* <a name="exp4"></a> Confirmed cases are used as a heuristic to determine how many cases are currently active in the week. Using Active cases (and eliminating deaths and recoveries) would not have given the accurate results anyways as recovery and death times differ significantly. However, confirmed cases reported in a particular time period clearly gives an indication of how the pandemic is spreading. Upon completing the analysis, the results obtained are extremely close to the actual peaks which reinforces the hypothesis that confirmed cases are good heuristic to measure the spread. The output file has the first line as the header.

* <a name="exp5"></a> The data is rectified to deal with the inconsistencies such as (but not limited to): dip in cumulative values, change in the name of headers.

<!-- ### last edited on 09-09-2021 by [utkarshg99](https://github.com/utkarshg99) -->